import io
import streamlit as st
import base64
import glob
import time
import numpy as np
import cv2 as cv
import pandas as pd
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.output_parsers import JsonOutputParser, CommaSeparatedListOutputParser
from langchain_core.messages import HumanMessage
from tqdm import tqdm
import os

# Your existing functions and configurations
def convert_to_base64(image_path):
    """Convert an image file to a Base64 encoded string."""
    try:
        with open(image_path, "rb") as image_file:
            base64_encoded_image = base64.b64encode(image_file.read())
            base64_string = base64_encoded_image.decode("utf-8")
            return base64_string
    except FileNotFoundError:
        print(f"File not found: {image_path}")
        return None
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

GOOGLE_API_KEY = "AIzaSyBmNZBBATXQff6-21ZZBne6tomVMskhp_E"

model_1_5_pro = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",
    temperature=0.01,
    google_api_key=GOOGLE_API_KEY,
)

def process_image(image_path):
    content = []
    image_data = convert_to_base64(image_path)
    
    gray_image = cv.imread(image_path, 0)
    thresh1 = cv.adaptiveThreshold(gray_image, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 11, 2)
    thresh2 = cv.adaptiveThreshold(gray_image, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 31, 3)
    thresh3 = cv.adaptiveThreshold(gray_image, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 13, 5)
    thresh4 = cv.adaptiveThreshold(gray_image, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 31, 4)
    final = np.concatenate((thresh1, thresh2, thresh3, thresh4), axis=1)

    ret, thresh1 = cv.threshold(gray_image, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)
    final1 = np.concatenate((thresh1, thresh2), axis=1)
    
    content.append(
        {
            "type": "text",
            "text": "Extract product information from the provided image for building the PSEG Gillette catalog for the attributes available in the image only.",
        }
    )
    
    content.append(
        {
            "type": "text",  
            "text": """Instructions:
- Analyze the image: Identify the product and its key attributes based on the visible information.
- Consider multilingual text: If the text is in multiple languages, extract the information value in the original language as in the image, and do not translate to English extract attributes in original language.
- Handle image clarity: If the original image lacks clarity to extract text, refer the preprocessed (grey scaled, adaptive threshold applied, inverted) versions to extract additional/missing information to complete the details.
- Avoid redundancy: Focus on completing missing attributes from one image using information from others images with original text. Remove duplicates in the attributes.
- Generate final values: Create a comprehensive product record with all extracted attributes. No two keys should have same values.""",
        }
    )
    content.append(
        {
            "type": "text",
            "text": "Original Image:"
        }
    )
    content.append(
        {
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{image_data}"},
        }
    )
    content.append(
        {
            "type": "text",
            "text": "Preprocessed Images:"
        }
    )
    for img_1 in [gray_image, final, final1]:
        imstring = base64.b64encode(cv.imencode('.jpg', img_1)[1]).decode()
        content.append(
            {
                "type": "image_url",
                "image_url": {"url": f"data:image/jpeg;base64,{imstring}"},
            }
        )
    
    content.append(
        {
            "type": "text",
            "text": "Convert Final response to JSON format",
        }
    )
    
    message = HumanMessage(content=content)
    
    try:
        chain = model_1_5_pro | JsonOutputParser()
        response = chain.invoke([message])
    except:
        try:
            chain = model_1_5_pro | JsonOutputParser()
            response = chain.invoke([message])
        except:
            chain = model_1_5_pro | CommaSeparatedListOutputParser()
            response = chain.invoke([message])
    
    return response

# Streamlit UI
st.set_page_config(page_title="Image to Text Processor", layout="wide")

st.title("Image to Text Processor")
st.write("Upload an image to extract product information for the PSEG Gillette catalog.")

uploaded_file = st.file_uploader("Choose an image file", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # Save the uploaded file temporarily
    with open("temp_image.jpg", "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    st.image(uploaded_file, caption="Uploaded Image", use_column_width=True)
    
    if st.button("Process Image"):
        with st.spinner("Processing image..."):
            result = process_image("temp_image.jpg")
        
        st.success("Image processed successfully!")
        st.json(result)
        
        # Convert result to DataFrame
        df = pd.DataFrame([result])
        
        # Create a download button for Excel file
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name="Sheet1")
        excel_data = output.getvalue()
        b64 = base64.b64encode(excel_data).decode()
        href = f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="results.xlsx">Download Excel File</a>'
        st.markdown(href, unsafe_allow_html=True)

    # Clean up the temporary file
    os.remove("temp_image.jpg")

st.sidebar.title("About")
st.sidebar.info("This application processes images to extract product information for the PSEG Gillette catalog. Upload an image, click 'Process Image', and view the results. You can also download the results in Excel format.")
